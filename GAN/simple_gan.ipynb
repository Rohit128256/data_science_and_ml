{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784',version=1,as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_x = mnist.data.reshape(-1,1,28,28)\n",
    "dataset_y = mnist.target.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(dataset_x)\n",
    "y_train = torch.tensor(dataset_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "LATENT_DIM = 64\n",
    "IN_CHANNELS = 1\n",
    "IM_SIZE = (28,28)\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 55\n",
    "NROWS = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINING THE GENERATOR CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.latent_dim = LATENT_DIM\n",
    "        self.img_size = IM_SIZE\n",
    "        self.channels = IN_CHANNELS\n",
    "        activation = nn.LeakyReLU()\n",
    "        layers_dim = [self.latent_dim,128,256,512,self.img_size[0]*self.img_size[1]*self.channels]\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(layers_dim[i],layers_dim[i+1]),\n",
    "                nn.BatchNorm1d(layers_dim[i+1]) if i != len(layers_dim) - 2 else nn.Identity(),\n",
    "                activation if i != len(layers_dim) - 2 else nn.Tanh() \n",
    "            )\n",
    "\n",
    "            for i in range(len(layers_dim)-1)\n",
    "        ])\n",
    "\n",
    "    def forward(self,z):\n",
    "        batch_size = z.shape[0]\n",
    "        out = z.reshape(-1,self.latent_dim)\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "        out = out.reshape(batch_size,self.channels,self.img_size[0],self.img_size[1])\n",
    "        return out\n",
    "    \n",
    "        \n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINING THE DISCRIMINATOR CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.img_size = IM_SIZE\n",
    "        self.channels = IN_CHANNELS\n",
    "        activation = nn.LeakyReLU()\n",
    "        layers_dim = [self.img_size[0]*self.img_size[1]*self.channels,512,256,128,1]\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(layers_dim[i],layers_dim[i+1]),\n",
    "                nn.LayerNorm(layers_dim[i+1]) if i != len(layers_dim) - 2 else nn.Identity(),\n",
    "                activation if i != len(layers_dim) - 2 else nn.Identity() \n",
    "            )\n",
    "\n",
    "            for i in range(len(layers_dim)-1)\n",
    "        ])\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = x.reshape(-1,self.img_size[0]*self.img_size[1]*self.channels)\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINING THE TRAIN FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    mnist_dataset = TensorDataset(x_train,y_train)\n",
    "    mnist_loader = DataLoader(mnist_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "    generator = Generator().to(device) # loaded the generator to gpu(if available)\n",
    "    generator.train() #training mode activated for generator\n",
    "\n",
    "    discriminator = Discriminator().to(device) # loaded the discriminator to gpu(if available)\n",
    "    discriminator.train() #training mode activated for discriminator\n",
    "\n",
    "    optimizer_generator = Adam(generator.parameters(), lr=1E-4, betas=(0.5,0.999))\n",
    "    optimizer_discriminator = Adam(discriminator.parameters(), lr=1E-4, betas=(0.5,0.999))\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    steps = 0\n",
    "    generated_sample_count = 0\n",
    "\n",
    "    for epoch_no in range(NUM_EPOCHS):\n",
    "        for im,label in tqdm(mnist_loader):\n",
    "            real_ims = im.float().to(device)\n",
    "            batch_size = real_ims.shape[0]\n",
    "\n",
    "\n",
    "            # optimize the discriminator first\n",
    "            optimizer_discriminator.zero_grad()\n",
    "            fake_im_noise = torch.randn((batch_size,LATENT_DIM),device=device)\n",
    "            fake_ims = generator(fake_im_noise) #generator generated images\n",
    "            real_label = torch.ones((batch_size,1), device=device)\n",
    "            fake_label = torch.zeros((batch_size,1),device=device)\n",
    "            disc_real_pred = discriminator(real_ims)\n",
    "            disc_fake_pred = discriminator(fake_ims.detach()) #detach is used to stop the gradient calculation for the generator\n",
    "            disc_real_loss = criterion(disc_real_pred.reshape(-1),real_label.reshape(-1))\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)  - \n",
      "(7, 0)  - \n",
      "(3, 6)  - \n",
      "(0, 4)  - \n",
      "(7, 9)  - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tp = [(1,2),(7,0),(3,6),(0,4),(7,9)]\n",
    "\n",
    "for x in tqdm(tp):\n",
    "    print(x,\" - \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
