{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784',version=1,as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_x = mnist.data.reshape(-1,1,28,28)\n",
    "dataset_y = mnist.target.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(dataset_x)\n",
    "y_train = torch.tensor(dataset_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "LATENT_DIM = 64\n",
    "IN_CHANNELS = 1\n",
    "IM_SIZE = (28,28)\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50\n",
    "NUM_SAMPLES = 225\n",
    "NROWS = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINING THE GENERATOR CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.latent_dim = LATENT_DIM\n",
    "        self.img_size = IM_SIZE\n",
    "        self.channels = IN_CHANNELS\n",
    "        activation = nn.LeakyReLU()\n",
    "        layers_dim = [self.latent_dim,128,256,512,self.img_size[0]*self.img_size[1]*self.channels]\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(layers_dim[i],layers_dim[i+1]),\n",
    "                nn.BatchNorm1d(layers_dim[i+1]) if i != len(layers_dim) - 2 else nn.Identity(),\n",
    "                activation if i != len(layers_dim) - 2 else nn.Tanh() \n",
    "            )\n",
    "\n",
    "            for i in range(len(layers_dim)-1)\n",
    "        ])\n",
    "\n",
    "    def forward(self,z):\n",
    "        batch_size = z.shape[0]\n",
    "        out = z.reshape(-1,self.latent_dim)\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "        out = out.reshape(batch_size,self.channels,self.img_size[0],self.img_size[1])\n",
    "        return out\n",
    "    \n",
    "        \n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINING THE DISCRIMINATOR CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.img_size = IM_SIZE\n",
    "        self.channels = IN_CHANNELS\n",
    "        activation = nn.LeakyReLU()\n",
    "        layers_dim = [self.img_size[0]*self.img_size[1]*self.channels,512,256,128,1]\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(layers_dim[i],layers_dim[i+1]),\n",
    "                nn.LayerNorm(layers_dim[i+1]) if i != len(layers_dim) - 2 else nn.Identity(),\n",
    "                activation if i != len(layers_dim) - 2 else nn.Identity() \n",
    "            )\n",
    "\n",
    "            for i in range(len(layers_dim)-1)\n",
    "        ])\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = x.reshape(-1,self.img_size[0]*self.img_size[1]*self.channels)\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_color_channels(images):\n",
    "\n",
    "    device = images.device\n",
    "    \n",
    "    # Generate random tints for the whole batch (batch_size, 1, 1) and broadcast across all images\n",
    "    # Make sure the random tint factors are within a reasonable range\n",
    "    red_tint = torch.rand(images.size(0), 1, 1, device=device) * 0.8 + 0.2  # Random red tint (0.2 to 1.0)\n",
    "    green_tint = torch.rand(images.size(0), 1, 1, device=device) * 0.8 + 0.2  # Random green tint (0.2 to 1.0)\n",
    "    blue_tint = torch.rand(images.size(0), 1, 1, device=device) * 0.8 + 0.2  # Random blue tint (0.2 to 1.0)\n",
    "    \n",
    "    # Apply the tints to the grayscale images (broadcasting over the batch)\n",
    "    red_channel = images * red_tint\n",
    "    green_channel = images * green_tint\n",
    "    blue_channel = images * blue_tint\n",
    "    \n",
    "    # Stack the 3 channels along a new dimension (batch_size, 3, 28, 28)\n",
    "    colored_images = torch.stack([red_channel, green_channel, blue_channel], dim=1)\n",
    "    \n",
    "    # Clip the values to stay within the range [0, 1]\n",
    "    colored_images = torch.clamp(colored_images, 0, 1)\n",
    "    \n",
    "    return colored_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINING THE TRAIN FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(generated_sample_count,generator):\n",
    "    fake_im_noise = torch.rand((NUM_SAMPLES,LATENT_DIM),device=device)\n",
    "    fake_ims = generator(fake_im_noise)\n",
    "    ims = torch.clamp(fake_ims, -1., 1.).detach().cpu()\n",
    "    ims = (ims + 1) / 2\n",
    "    grid = make_grid(ims,nrow=NROWS)\n",
    "    img = torchvision.transforms.ToPILImage()(grid)\n",
    "    if not os.path.exists('samples'):\n",
    "        os.makedirs('samples')\n",
    "    img.save('samples/{}.png'.format(generated_sample_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    mnist_dataset = TensorDataset(x_train,y_train)\n",
    "    mnist_loader = DataLoader(mnist_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "    generator = Generator().to(device) # loaded the generator to gpu(if available)\n",
    "    generator.train() #training mode activated for generator\n",
    "\n",
    "    discriminator = Discriminator().to(device) # loaded the discriminator to gpu(if available)\n",
    "    discriminator.train() #training mode activated for discriminator\n",
    "\n",
    "    optimizer_generator = Adam(generator.parameters(), lr=1E-4, betas=(0.5,0.999))\n",
    "    optimizer_discriminator = Adam(discriminator.parameters(), lr=1E-4, betas=(0.5,0.999))\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    steps = 0\n",
    "    generated_sample_count = 0\n",
    "\n",
    "    for epoch_no in range(NUM_EPOCHS):\n",
    "        print(\"Epoch no - \",epoch_no+1,\"/\",NUM_EPOCHS)\n",
    "        for im,label in tqdm(mnist_loader):\n",
    "            real_ims = im.float().to(device)\n",
    "            batch_size = real_ims.shape[0]\n",
    "\n",
    "\n",
    "            # optimize the discriminator first\n",
    "            optimizer_discriminator.zero_grad()\n",
    "            fake_im_noise = torch.randn((batch_size,LATENT_DIM),device=device)\n",
    "            fake_ims = generator(fake_im_noise) #generator generated images\n",
    "            real_label = torch.ones((batch_size,1), device=device)\n",
    "            fake_label = torch.zeros((batch_size,1),device=device)\n",
    "            disc_real_pred = discriminator(real_ims)\n",
    "            disc_fake_pred = discriminator(fake_ims.detach()) #detach is used to stop the gradient calculation for the generator\n",
    "            disc_real_loss = criterion(disc_real_pred.reshape(-1),real_label.reshape(-1))\n",
    "            disc_fake_loss = criterion(disc_fake_pred.reshape(-1),fake_label.reshape(-1)) \n",
    "            disc_loss = (disc_real_loss + disc_fake_loss)/2\n",
    "            disc_loss.backward()\n",
    "            optimizer_discriminator.step()\n",
    "\n",
    "            # now optimize the Generator\n",
    "            optimizer_generator.zero_grad()\n",
    "            fake_im_noise = torch.randn((batch_size,LATENT_DIM),device=device)\n",
    "            fake_ims = generator(fake_im_noise)  #generator generated images\n",
    "            disc_fake_pred = discriminator(fake_ims)\n",
    "            gen_fake_loss = criterion(disc_fake_pred.reshape(-1),real_label.reshape(-1))\n",
    "            gen_fake_loss.backward()\n",
    "            optimizer_generator.step()\n",
    "\n",
    "            #save samples\n",
    "\n",
    "            if (steps % 300) == 0:\n",
    "                with torch.no_grad():\n",
    "                    generator.eval() # switch the generator to evaluation mode\n",
    "                    infer(generated_sample_count,generator)\n",
    "                    generated_sample_count += 1\n",
    "                    generator.train() # again switched to training mode\n",
    "            steps += 1\n",
    "            \n",
    "        torch.save(generator.state_dict(),'generator_ckpt.pth')\n",
    "        torch.save(discriminator.state_dict(),'discriminator_ckpt.pth')\n",
    "\n",
    "    print('Done Training.....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
